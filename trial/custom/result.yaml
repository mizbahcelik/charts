---
# Source: hazelcast/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: test-custom-hazelcast
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.2
    app.kubernetes.io/instance: "test-custom"
    app.kubernetes.io/managed-by: "Helm"
---
# Source: hazelcast/templates/config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: test-custom-hazelcast-configuration
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.2
    app.kubernetes.io/instance: "test-custom"
    app.kubernetes.io/managed-by: "Helm"
data:
  hazelcast.yaml: |-
    hazelcast:
      jet:
        enabled: ${hz.jet.enabled}
      network:
        join:
          kubernetes:
            enabled: true
            namespace: ${namespace}
            service-name: ${serviceName}
        rest-api:
          enabled: true
---
# Source: hazelcast/templates/mancenter-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: test-custom-hazelcast-mancenter-configuration
  labels:
    app.kubernetes.io/name: hazelcast-mancenter
    helm.sh/chart: hazelcast-5.4.2
    app.kubernetes.io/instance: "test-custom"
    app.kubernetes.io/managed-by: "Helm"
data:
  hazelcast-client.yaml: |-
    hazelcast-client:
      network:
        kubernetes:
          enabled: true
          namespace: ${namespace}
          service-name: ${serviceName}
---
# Source: hazelcast/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: test-custom-hazelcast-default
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.2
    app.kubernetes.io/instance: "test-custom"
    app.kubernetes.io/managed-by: "Helm"
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  - pods
  - nodes
  - services
  verbs:
  - get
  - list
---
# Source: hazelcast/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: test-custom-hazelcast-default
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.2
    app.kubernetes.io/instance: "test-custom"
    app.kubernetes.io/managed-by: "Helm"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: test-custom-hazelcast-default
subjects:
- kind: ServiceAccount
  name: test-custom-hazelcast
  namespace: default
---
# Source: hazelcast/templates/mancenter-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: test-custom-hazelcast-mancenter
  labels:
    app.kubernetes.io/name: hazelcast-mancenter
    helm.sh/chart: hazelcast-5.4.2
    app.kubernetes.io/instance: "test-custom"
    app.kubernetes.io/managed-by: "Helm"
spec:
  type: LoadBalancer
  selector:
    app.kubernetes.io/name: hazelcast-mancenter
    app.kubernetes.io/instance: "test-custom"
    role: mancenter
  ports:
  - protocol: TCP
    port: 8080
    targetPort: mancenter
    name: http
  - protocol: TCP
    port: 443
    targetPort: mancenter
    name: https
---
# Source: hazelcast/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: test-custom-hazelcast
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.2
    app.kubernetes.io/instance: "test-custom"
    app.kubernetes.io/managed-by: "Helm"
spec:
  type: ClusterIP
  clusterIP: None
  selector:
    app.kubernetes.io/name: hazelcast
    app.kubernetes.io/instance: "test-custom"
    role: hazelcast
  ports:
  - protocol: TCP
    port: 5701
    targetPort: hazelcast
    name: hzport
---
# Source: hazelcast/templates/mancenter-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: test-custom-hazelcast-mancenter
  labels:
    app.kubernetes.io/name: hazelcast-mancenter
    helm.sh/chart: hazelcast-5.4.2
    app.kubernetes.io/instance: "test-custom"
    app.kubernetes.io/managed-by: "Helm"
spec:
  serviceName: test-custom-hazelcast-mancenter
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: hazelcast-mancenter
      app.kubernetes.io/instance: "test-custom"
      role: mancenter
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hazelcast-mancenter
        helm.sh/chart: hazelcast-5.4.2
        app.kubernetes.io/instance: "test-custom"
        app.kubernetes.io/managed-by: "Helm"
        role: mancenter
    spec:
      hostNetwork: false
      hostPID: false
      hostIPC: false
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        runAsGroup: 65534
        fsGroup: 65534
      containers:
      - name: test-custom-hazelcast-mancenter
        image: "hazelcast/management-center:5.1.3"
        imagePullPolicy: "IfNotPresent"
        resources:
          null
        ports:
        - name: mancenter
          containerPort: 8080
        livenessProbe:
          httpGet:
            path: /health
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
        readinessProbe:
          tcpSocket:
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 1
          successThreshold: 1
          failureThreshold: 3
        volumeMounts:
        - name: config
          mountPath: /config
        - name: mancenter-storage
          mountPath: /data
        env:
        
        
        
        
        
        - name: MC_INIT_CMD
          value: "./bin/mc-conf.sh cluster add --lenient=true -H /data -cc /config/hazelcast-client.yaml; "
        - name: JAVA_OPTS
          value: " -Dhazelcast.mc.healthCheck.enable=true -DserviceName=test-custom-hazelcast -Dnamespace=default -Dhazelcast.mc.tls.enabled=false "
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
          runAsGroup: 65534
          privileged: false
          readOnlyRootFilesystem: false
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
      securityContext:
        fsGroup: 65534
      serviceAccountName: test-custom-hazelcast
      automountServiceAccountToken: true
      volumes:
      - name: config
        configMap:
           name: test-custom-hazelcast-mancenter-configuration
      - name: mancenter-storage
    
  volumeClaimTemplates:
  - metadata:
      name: mancenter-storage
      labels:
        app.kubernetes.io/name: hazelcast-mancenter
        helm.sh/chart: "hazelcast-5.4.2"
        app.kubernetes.io/instance: "test-custom"
        app.kubernetes.io/managed-by: "Helm"
    spec:
      accessModes:
        - "ReadWriteOnce"
      resources:
        requests:
          storage: "8Gi"
---
# Source: hazelcast/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: test-custom-hazelcast
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.2
    app.kubernetes.io/instance: "test-custom"
    app.kubernetes.io/managed-by: "Helm"
  annotations:
spec:
  serviceName: test-custom-hazelcast
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: hazelcast
      app.kubernetes.io/instance: "test-custom"
      role: hazelcast
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hazelcast
        helm.sh/chart: hazelcast-5.4.2
        app.kubernetes.io/instance: "test-custom"
        app.kubernetes.io/managed-by: "Helm"
        role: hazelcast
      annotations:
        checksum/hazelcast-config: c4b6a3fd48054c4013ca0c642202dfc072f46a56dd9e0062a942d6a8f565cb18
    spec:
      terminationGracePeriodSeconds: 600
      hostNetwork: false
      hostPID: false
      hostIPC: false
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        runAsGroup: 65534
        fsGroup: 65534
      containers:
      - name: test-custom-hazelcast
        image: "hazelcast/hazelcast:5.1.2"
        imagePullPolicy: "IfNotPresent"
        resources:
          null
        ports:
        - name: hazelcast
          containerPort: 5701
          hostPort: 5701
        livenessProbe:
          httpGet:
            path: /hazelcast/health/node-state
            port: 5701
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 10
          successThreshold: 1
          failureThreshold: 10
        readinessProbe:
          httpGet:
            path: /hazelcast/health/node-state
            port: 5701
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 10
          successThreshold: 1
          failureThreshold: 10
        volumeMounts:
        - name: hazelcast-storage
          mountPath: /data/hazelcast
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: JAVA_OPTS
          value: "-Dhazelcast.config=/data/hazelcast/hazelcast.yaml -DserviceName=test-custom-hazelcast -Dnamespace=default -Dhz.jet.enabled=true -Dhazelcast.shutdownhook.policy=GRACEFUL -Dhazelcast.shutdownhook.enabled=true -Dhazelcast.graceful.shutdown.max.wait=600   "
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
          runAsGroup: 65534
          privileged: false
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
      serviceAccountName: test-custom-hazelcast
      automountServiceAccountToken: true
      volumes:
      - name: hazelcast-storage
        configMap:
          name: test-custom-hazelcast-configuration
---
# Source: hazelcast/templates/tests/test-hazelcast.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "test-custom-hazelcast-test-6eaao"
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-delete-policy": hook-succeeded, hook-failed
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.2
    app.kubernetes.io/instance: "test-custom"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/component: "test"
    role: test
spec:
  containers:
  - name: "test-custom-hazelcast-test"
    image: "alpine:latest"
    command:
    - "sh"
    - "-c"
    - |
      set -ex
      # Install required test tools
      apk add -q curl
      # Get the number of Hazelcast members in the cluster
      CLUSTER_SIZE=$(curl test-custom-hazelcast:5701/hazelcast/health/cluster-size)
      # Test the correct number of Hazelcast members
      test ${CLUSTER_SIZE} -eq 3
    resources:
      null
  restartPolicy: Never
---
# Source: hazelcast/templates/tests/test-management-center.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "test-custom-hazelcast-mancenter-test-gkbwe"
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-delete-policy": hook-succeeded, hook-failed
  labels:
    app.kubernetes.io/name: hazelcast
    helm.sh/chart: hazelcast-5.4.2
    app.kubernetes.io/instance: "test-custom"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/component: "test"
    role: test
spec:
  containers:
  - name: "test-custom-hazelcast-mancenter-test"
    image: "alpine:latest"
    command:
    - "sh"
    - "-c"
    - |
      set -ex
      # Install required test tools
      apk add -q jq curl
      # Get the HTTP Response Code of the Health Check
      HEALTH_CHECK_HTTP_RESPONSE_CODE=$(curl --write-out %{http_code} --silent --output /dev/null test-custom-hazelcast-mancenter:8080/health)
      # Test the MC HTTP RESPONSE CODE
      test ${HEALTH_CHECK_HTTP_RESPONSE_CODE} -eq 200
      # Get the connected cluster count via /rest/clusters/dev/members endpoint
      CONNECTED_CLUSTER_SIZE=$(curl --silent test-custom-hazelcast-mancenter:8080/rest/clusters/dev/members | jq '. | length')
      # Test the correct number of Hazelcast members
      test ${CONNECTED_CLUSTER_SIZE} -eq 3
    resources:
      null
  restartPolicy: Never
